{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "331ff7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\Anaconda\\envs\\tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda\\envs\\tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda\\envs\\tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda\\envs\\tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda\\envs\\tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda\\envs\\tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "#tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6740374",
   "metadata": {},
   "source": [
    "### Data inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "435cdf33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/train.csv\")\n",
    "df.head()\n",
    "df.isnull().sum()\n",
    "df.notnull().sum()\n",
    "df.info()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd52ac24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different values at the 'Embarked' column: 3\n",
      "Different values at the 'Cabin' column: 147\n",
      "Different values at the 'Ticket' column: 681\n",
      "Different values at the 'Name' column: 891\n",
      "Differnt values at the 'Sex' column: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Different values at the 'Embarked' column: %d\" %df['Embarked'].value_counts().shape[0])\n",
    "print(\"Different values at the 'Cabin' column: %d\" %df['Cabin'].value_counts().shape[0])\n",
    "print(\"Different values at the 'Ticket' column: %d\" %df['Ticket'].value_counts().shape[0])\n",
    "print(\"Different values at the 'Name' column: %d\" %df['Name'].value_counts().shape[0])\n",
    "print(\"Differnt values at the 'Sex' column: %d\" %df['Sex'].value_counts().shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecf7fd2",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "\n",
    "Replacing null values  \n",
    "Removing columns with many missing values and unuseful like 'Name' and 'Ticket'  \n",
    "One-hot encoding categorical variables for Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b04ca493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace null Values (np.nan) with mean\n",
    "df['Age'] = df['Age'].replace(np.nan, df['Age'].mean())\n",
    "# Replacing the null values with the most frequent value\n",
    "df['Embarked'] = df['Embarked'].fillna(df['Embarked'].value_counts().index[0])\n",
    "# Replacing null values with Unknown Class\n",
    "df['Cabin'] = df['Cabin'].fillna('Unknown')\n",
    "\n",
    "# Removing unused columns\n",
    "UNUSED_COLUMNS = [\"Name\", \"Ticket\", \"Cabin\"]\n",
    "df = df.drop(UNUSED_COLUMNS, axis=1)\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "df = pd.get_dummies(df, columns=['Embarked', 'Sex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3368c2",
   "metadata": {},
   "source": [
    "### Function to split the dataset into train, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c02ad6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_partitions_pd(df, train_split=0.8, val_split=0.1, test_split=0.1):\n",
    "    assert (train_split + test_split + val_split) == 1\n",
    "\n",
    "    # Specify seed to always have the same split distribution between runs\n",
    "    # df.samples shuffles the dataframe\n",
    "    df_sample = df.sample(frac=1, random_state=12)\n",
    "    indices_or_sections = [int(train_split * len(df)), int((1 - val_split) * len(df))]\n",
    "    \n",
    "    train_ds, test_ds, val_ds = np.split(df_sample, indices_or_sections)\n",
    "    \n",
    "    return train_ds, val_ds, test_ds\n",
    "\n",
    "train_df, val_df, test_df = get_dataset_partitions_pd(df, train_split=0.8, val_split=0, test_split=0.2)\n",
    "y_train = train_df['Survived']\n",
    "X_train = train_df.drop(columns='Survived')\n",
    "y_test = test_df['Survived']\n",
    "X_test = test_df.drop(columns='Survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731b11c6",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff80cc21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 569 samples, validate on 143 samples\n",
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/80\n",
      "569/569 [==============================] - 0s 357us/sample - loss: 8.1777 - binary_accuracy: 0.3972 - val_loss: 8.5871 - val_binary_accuracy: 0.3427\n",
      "Epoch 2/80\n",
      "569/569 [==============================] - 0s 21us/sample - loss: 6.5280 - binary_accuracy: 0.4077 - val_loss: 4.0063 - val_binary_accuracy: 0.6154\n",
      "Epoch 3/80\n",
      "569/569 [==============================] - 0s 19us/sample - loss: 4.4682 - binary_accuracy: 0.6239 - val_loss: 3.3102 - val_binary_accuracy: 0.5315\n",
      "Epoch 4/80\n",
      "569/569 [==============================] - 0s 19us/sample - loss: 3.0945 - binary_accuracy: 0.4815 - val_loss: 3.2068 - val_binary_accuracy: 0.6014\n",
      "Epoch 5/80\n",
      "569/569 [==============================] - 0s 21us/sample - loss: 2.8132 - binary_accuracy: 0.5325 - val_loss: 2.6796 - val_binary_accuracy: 0.5734\n",
      "Epoch 6/80\n",
      "569/569 [==============================] - 0s 19us/sample - loss: 2.3684 - binary_accuracy: 0.5255 - val_loss: 2.0881 - val_binary_accuracy: 0.5455\n",
      "Epoch 7/80\n",
      "569/569 [==============================] - 0s 21us/sample - loss: 1.8158 - binary_accuracy: 0.5413 - val_loss: 1.5053 - val_binary_accuracy: 0.6294\n",
      "Epoch 8/80\n",
      "569/569 [==============================] - 0s 21us/sample - loss: 1.1768 - binary_accuracy: 0.5536 - val_loss: 0.7167 - val_binary_accuracy: 0.6503\n",
      "Epoch 9/80\n",
      "569/569 [==============================] - 0s 19us/sample - loss: 0.9000 - binary_accuracy: 0.5940 - val_loss: 0.6192 - val_binary_accuracy: 0.6923\n",
      "Epoch 10/80\n",
      "569/569 [==============================] - 0s 19us/sample - loss: 0.8364 - binary_accuracy: 0.6591 - val_loss: 0.5975 - val_binary_accuracy: 0.6993\n",
      "Epoch 11/80\n",
      "569/569 [==============================] - 0s 19us/sample - loss: 0.8039 - binary_accuracy: 0.6380 - val_loss: 0.6309 - val_binary_accuracy: 0.6783\n",
      "Epoch 12/80\n",
      "569/569 [==============================] - 0s 19us/sample - loss: 0.8088 - binary_accuracy: 0.6063 - val_loss: 0.7356 - val_binary_accuracy: 0.5804\n",
      "Epoch 13/80\n",
      "569/569 [==============================] - 0s 19us/sample - loss: 0.7276 - binary_accuracy: 0.6520 - val_loss: 0.5816 - val_binary_accuracy: 0.7273\n",
      "Epoch 14/80\n",
      "569/569 [==============================] - 0s 19us/sample - loss: 0.7214 - binary_accuracy: 0.6731 - val_loss: 0.5366 - val_binary_accuracy: 0.7832\n",
      "Epoch 15/80\n",
      "569/569 [==============================] - 0s 19us/sample - loss: 0.6750 - binary_accuracy: 0.7118 - val_loss: 0.5356 - val_binary_accuracy: 0.7413\n",
      "Epoch 16/80\n",
      "569/569 [==============================] - 0s 19us/sample - loss: 0.7000 - binary_accuracy: 0.6749 - val_loss: 0.5302 - val_binary_accuracy: 0.7832\n",
      "Epoch 17/80\n",
      "569/569 [==============================] - 0s 19us/sample - loss: 0.6462 - binary_accuracy: 0.7065 - val_loss: 0.5495 - val_binary_accuracy: 0.7552\n",
      "Epoch 18/80\n",
      "569/569 [==============================] - 0s 18us/sample - loss: 0.6157 - binary_accuracy: 0.6995 - val_loss: 0.5319 - val_binary_accuracy: 0.7622\n",
      "Epoch 19/80\n",
      "569/569 [==============================] - 0s 18us/sample - loss: 0.5904 - binary_accuracy: 0.7188 - val_loss: 0.5218 - val_binary_accuracy: 0.7692\n",
      "Epoch 20/80\n",
      "569/569 [==============================] - 0s 18us/sample - loss: 0.5732 - binary_accuracy: 0.7223 - val_loss: 0.5160 - val_binary_accuracy: 0.7692\n",
      "Epoch 21/80\n",
      "569/569 [==============================] - 0s 18us/sample - loss: 0.5689 - binary_accuracy: 0.7293 - val_loss: 0.5817 - val_binary_accuracy: 0.6783\n",
      "Epoch 22/80\n",
      "569/569 [==============================] - ETA: 0s - loss: 0.5704 - binary_accuracy: 0.700 - 0s 18us/sample - loss: 0.5591 - binary_accuracy: 0.7258 - val_loss: 0.5037 - val_binary_accuracy: 0.7692\n",
      "Epoch 23/80\n",
      "569/569 [==============================] - 0s 19us/sample - loss: 0.5521 - binary_accuracy: 0.7364 - val_loss: 0.5017 - val_binary_accuracy: 0.7552\n",
      "Epoch 24/80\n",
      "569/569 [==============================] - 0s 19us/sample - loss: 0.5522 - binary_accuracy: 0.7188 - val_loss: 0.5046 - val_binary_accuracy: 0.7692\n",
      "Epoch 25/80\n",
      "569/569 [==============================] - 0s 19us/sample - loss: 0.5563 - binary_accuracy: 0.7329 - val_loss: 0.5433 - val_binary_accuracy: 0.7133\n",
      "Epoch 26/80\n",
      "569/569 [==============================] - 0s 23us/sample - loss: 0.5627 - binary_accuracy: 0.7118 - val_loss: 0.5537 - val_binary_accuracy: 0.7203\n",
      "Epoch 27/80\n",
      "569/569 [==============================] - 0s 19us/sample - loss: 0.5513 - binary_accuracy: 0.7241 - val_loss: 0.5008 - val_binary_accuracy: 0.7762\n",
      "Epoch 28/80\n",
      "569/569 [==============================] - 0s 18us/sample - loss: 0.5730 - binary_accuracy: 0.7153 - val_loss: 0.5062 - val_binary_accuracy: 0.7692\n",
      "Epoch 29/80\n",
      "569/569 [==============================] - 0s 19us/sample - loss: 0.5771 - binary_accuracy: 0.7135 - val_loss: 0.5305 - val_binary_accuracy: 0.7343\n",
      "Epoch 30/80\n",
      "569/569 [==============================] - 0s 21us/sample - loss: 0.5549 - binary_accuracy: 0.7206 - val_loss: 0.4932 - val_binary_accuracy: 0.7692\n",
      "Epoch 31/80\n",
      "569/569 [==============================] - 0s 26us/sample - loss: 0.5083 - binary_accuracy: 0.7540 - val_loss: 0.4921 - val_binary_accuracy: 0.7832\n",
      "Epoch 32/80\n",
      "569/569 [==============================] - 0s 21us/sample - loss: 0.5017 - binary_accuracy: 0.7557 - val_loss: 0.4905 - val_binary_accuracy: 0.7692\n",
      "Epoch 33/80\n",
      "569/569 [==============================] - 0s 18us/sample - loss: 0.5131 - binary_accuracy: 0.7610 - val_loss: 0.5870 - val_binary_accuracy: 0.6923\n",
      "Epoch 34/80\n",
      "569/569 [==============================] - 0s 19us/sample - loss: 0.5212 - binary_accuracy: 0.7434 - val_loss: 0.5009 - val_binary_accuracy: 0.7762\n",
      "Epoch 35/80\n",
      "569/569 [==============================] - 0s 18us/sample - loss: 0.5318 - binary_accuracy: 0.7346 - val_loss: 0.4776 - val_binary_accuracy: 0.7762\n",
      "Epoch 36/80\n",
      "569/569 [==============================] - 0s 19us/sample - loss: 0.4950 - binary_accuracy: 0.7540 - val_loss: 0.4796 - val_binary_accuracy: 0.7762\n",
      "Epoch 37/80\n",
      "569/569 [==============================] - 0s 18us/sample - loss: 0.5032 - binary_accuracy: 0.7540 - val_loss: 0.4777 - val_binary_accuracy: 0.7832\n",
      "Epoch 38/80\n",
      "569/569 [==============================] - 0s 18us/sample - loss: 0.5354 - binary_accuracy: 0.7153 - val_loss: 0.4928 - val_binary_accuracy: 0.8042\n",
      "Epoch 39/80\n",
      "569/569 [==============================] - 0s 19us/sample - loss: 0.5138 - binary_accuracy: 0.7575 - val_loss: 0.4652 - val_binary_accuracy: 0.7902\n",
      "Epoch 40/80\n",
      "569/569 [==============================] - 0s 18us/sample - loss: 0.5169 - binary_accuracy: 0.7469 - val_loss: 0.5450 - val_binary_accuracy: 0.7203\n",
      "Epoch 41/80\n",
      "569/569 [==============================] - 0s 19us/sample - loss: 0.5103 - binary_accuracy: 0.7575 - val_loss: 0.4894 - val_binary_accuracy: 0.7902\n",
      "Epoch 42/80\n",
      "569/569 [==============================] - 0s 18us/sample - loss: 0.5002 - binary_accuracy: 0.7469 - val_loss: 0.4838 - val_binary_accuracy: 0.7902\n",
      "Epoch 43/80\n",
      "569/569 [==============================] - 0s 18us/sample - loss: 0.5442 - binary_accuracy: 0.7434 - val_loss: 0.4740 - val_binary_accuracy: 0.7902\n",
      "Epoch 44/80\n",
      "569/569 [==============================] - 0s 19us/sample - loss: 0.5485 - binary_accuracy: 0.7188 - val_loss: 0.5008 - val_binary_accuracy: 0.7902\n",
      "Epoch 45/80\n",
      "569/569 [==============================] - ETA: 0s - loss: 0.5557 - binary_accuracy: 0.700 - 0s 18us/sample - loss: 0.5071 - binary_accuracy: 0.7540 - val_loss: 0.4935 - val_binary_accuracy: 0.7692\n",
      "Epoch 46/80\n",
      "569/569 [==============================] - 0s 18us/sample - loss: 0.4989 - binary_accuracy: 0.7768 - val_loss: 0.5274 - val_binary_accuracy: 0.7692\n",
      "Epoch 47/80\n",
      "569/569 [==============================] - 0s 19us/sample - loss: 0.4920 - binary_accuracy: 0.7645 - val_loss: 0.4835 - val_binary_accuracy: 0.7902\n",
      "Epoch 48/80\n",
      "569/569 [==============================] - 0s 17us/sample - loss: 0.5120 - binary_accuracy: 0.7575 - val_loss: 0.5628 - val_binary_accuracy: 0.7133\n",
      "Epoch 49/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569/569 [==============================] - 0s 19us/sample - loss: 0.5176 - binary_accuracy: 0.7504 - val_loss: 0.4925 - val_binary_accuracy: 0.7762\n",
      "Epoch 50/80\n",
      "569/569 [==============================] - 0s 19us/sample - loss: 0.5074 - binary_accuracy: 0.7540 - val_loss: 0.4898 - val_binary_accuracy: 0.7902\n",
      "Epoch 51/80\n",
      "569/569 [==============================] - 0s 19us/sample - loss: 0.4965 - binary_accuracy: 0.7663 - val_loss: 0.4809 - val_binary_accuracy: 0.8042\n",
      "Epoch 52/80\n",
      "569/569 [==============================] - 0s 18us/sample - loss: 0.4924 - binary_accuracy: 0.7557 - val_loss: 0.5283 - val_binary_accuracy: 0.7413\n",
      "Epoch 53/80\n",
      "569/569 [==============================] - 0s 18us/sample - loss: 0.5624 - binary_accuracy: 0.7276 - val_loss: 0.5993 - val_binary_accuracy: 0.6923\n",
      "Epoch 54/80\n",
      "569/569 [==============================] - 0s 18us/sample - loss: 0.6071 - binary_accuracy: 0.7153 - val_loss: 0.7737 - val_binary_accuracy: 0.5874\n",
      "Epoch 55/80\n",
      "569/569 [==============================] - 0s 19us/sample - loss: 0.5673 - binary_accuracy: 0.7223 - val_loss: 0.4606 - val_binary_accuracy: 0.7972\n",
      "Epoch 56/80\n",
      "569/569 [==============================] - 0s 18us/sample - loss: 0.5442 - binary_accuracy: 0.7293 - val_loss: 0.4547 - val_binary_accuracy: 0.7972\n",
      "Epoch 57/80\n",
      "569/569 [==============================] - 0s 16us/sample - loss: 0.6056 - binary_accuracy: 0.7047 - val_loss: 0.5753 - val_binary_accuracy: 0.7203\n",
      "Epoch 58/80\n",
      "569/569 [==============================] - 0s 18us/sample - loss: 0.5359 - binary_accuracy: 0.7452 - val_loss: 0.5319 - val_binary_accuracy: 0.7413\n",
      "Epoch 59/80\n",
      "569/569 [==============================] - 0s 18us/sample - loss: 0.5151 - binary_accuracy: 0.7663 - val_loss: 0.4754 - val_binary_accuracy: 0.7972\n",
      "Epoch 60/80\n",
      "569/569 [==============================] - 0s 18us/sample - loss: 0.5405 - binary_accuracy: 0.7452 - val_loss: 0.6415 - val_binary_accuracy: 0.6783\n",
      "Epoch 61/80\n",
      "569/569 [==============================] - 0s 18us/sample - loss: 0.5606 - binary_accuracy: 0.7329 - val_loss: 0.4685 - val_binary_accuracy: 0.7832\n",
      "Epoch 62/80\n",
      "569/569 [==============================] - 0s 19us/sample - loss: 0.5062 - binary_accuracy: 0.7698 - val_loss: 0.5700 - val_binary_accuracy: 0.6993\n",
      "Epoch 63/80\n",
      "569/569 [==============================] - 0s 17us/sample - loss: 0.5021 - binary_accuracy: 0.7698 - val_loss: 0.4497 - val_binary_accuracy: 0.8042\n",
      "Epoch 64/80\n",
      "569/569 [==============================] - 0s 16us/sample - loss: 0.4805 - binary_accuracy: 0.7803 - val_loss: 0.4876 - val_binary_accuracy: 0.7972\n",
      "Epoch 65/80\n",
      "569/569 [==============================] - 0s 19us/sample - loss: 0.4886 - binary_accuracy: 0.7838 - val_loss: 0.4689 - val_binary_accuracy: 0.7902\n",
      "Epoch 66/80\n",
      "569/569 [==============================] - 0s 18us/sample - loss: 0.4902 - binary_accuracy: 0.7715 - val_loss: 0.4572 - val_binary_accuracy: 0.7972\n",
      "Epoch 67/80\n",
      "569/569 [==============================] - 0s 19us/sample - loss: 0.4813 - binary_accuracy: 0.7786 - val_loss: 0.4567 - val_binary_accuracy: 0.8112\n",
      "Epoch 68/80\n",
      "569/569 [==============================] - 0s 16us/sample - loss: 0.4746 - binary_accuracy: 0.7909 - val_loss: 0.4773 - val_binary_accuracy: 0.7832\n",
      "Epoch 69/80\n",
      "569/569 [==============================] - 0s 18us/sample - loss: 0.4853 - binary_accuracy: 0.7733 - val_loss: 0.4772 - val_binary_accuracy: 0.8042\n",
      "Epoch 70/80\n",
      "569/569 [==============================] - 0s 18us/sample - loss: 0.5119 - binary_accuracy: 0.7663 - val_loss: 0.4618 - val_binary_accuracy: 0.8042\n",
      "Epoch 71/80\n",
      "569/569 [==============================] - 0s 17us/sample - loss: 0.5188 - binary_accuracy: 0.7452 - val_loss: 0.5709 - val_binary_accuracy: 0.7133\n",
      "Epoch 72/80\n",
      "569/569 [==============================] - 0s 19us/sample - loss: 0.5290 - binary_accuracy: 0.7610 - val_loss: 0.4465 - val_binary_accuracy: 0.8112\n",
      "Epoch 73/80\n",
      "569/569 [==============================] - 0s 18us/sample - loss: 0.4815 - binary_accuracy: 0.7768 - val_loss: 0.5193 - val_binary_accuracy: 0.7552\n",
      "Epoch 74/80\n",
      "569/569 [==============================] - 0s 19us/sample - loss: 0.5180 - binary_accuracy: 0.7575 - val_loss: 0.4987 - val_binary_accuracy: 0.7692\n",
      "Epoch 75/80\n",
      "569/569 [==============================] - 0s 16us/sample - loss: 0.5158 - binary_accuracy: 0.7768 - val_loss: 0.5650 - val_binary_accuracy: 0.7273\n",
      "Epoch 76/80\n",
      "569/569 [==============================] - 0s 18us/sample - loss: 0.5053 - binary_accuracy: 0.7680 - val_loss: 0.4487 - val_binary_accuracy: 0.8112\n",
      "Epoch 77/80\n",
      "569/569 [==============================] - 0s 18us/sample - loss: 0.5367 - binary_accuracy: 0.7715 - val_loss: 0.5359 - val_binary_accuracy: 0.7343\n",
      "Epoch 78/80\n",
      "569/569 [==============================] - 0s 19us/sample - loss: 0.4818 - binary_accuracy: 0.7873 - val_loss: 0.4498 - val_binary_accuracy: 0.7972\n",
      "Epoch 79/80\n",
      "569/569 [==============================] - 0s 19us/sample - loss: 0.4812 - binary_accuracy: 0.7821 - val_loss: 0.4596 - val_binary_accuracy: 0.8042\n",
      "Epoch 80/80\n",
      "569/569 [==============================] - 0s 18us/sample - loss: 0.4844 - binary_accuracy: 0.7786 - val_loss: 0.4567 - val_binary_accuracy: 0.7972\n"
     ]
    }
   ],
   "source": [
    "# Softmax for multiclass classification problem\n",
    "# Relu activation function\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(32, input_shape=(X_train.shape[1],), activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "acc = tf.keras.metrics.BinaryAccuracy()\n",
    "\n",
    "model.compile(optimizer, loss=loss, metrics=[acc])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "            batch_size=50,\n",
    "            epochs=80,\n",
    "            verbose=1,\n",
    "            validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d3ba044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Networks Accuracy: 81.56%\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "metric = tf.keras.metrics.BinaryAccuracy()\n",
    "metric.update_state(y_test,y_pred)\n",
    "nn_accuracy = metric.result().numpy()\n",
    "print(\"Neural Networks Accuracy: %.2f%%\" % (nn_accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed4a42a",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e30a6fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=2)\n",
    "model.fit(X_train, y_train)\n",
    "y_prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9e6b526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Accuracy: 83.80%\n"
     ]
    }
   ],
   "source": [
    "rf_accuracy = accuracy_score(y_test, y_prediction)\n",
    "print(\"RF Accuracy: %.2f%%\" % (rf_accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642c3b88",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39fd291d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcc78e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.91038\tvalidation_0-error:0.16201\tvalidation_0-error@0.6:0.19553\n",
      "[1]\tvalidation_0-auc:0.90741\tvalidation_0-error:0.17318\tvalidation_0-error@0.6:0.15643\n",
      "[2]\tvalidation_0-auc:0.91257\tvalidation_0-error:0.18436\tvalidation_0-error@0.6:0.16760\n",
      "[3]\tvalidation_0-auc:0.91296\tvalidation_0-error:0.17318\tvalidation_0-error@0.6:0.16760\n",
      "[4]\tvalidation_0-auc:0.91322\tvalidation_0-error:0.16760\tvalidation_0-error@0.6:0.16201\n",
      "[5]\tvalidation_0-auc:0.90876\tvalidation_0-error:0.16760\tvalidation_0-error@0.6:0.16760\n",
      "[6]\tvalidation_0-auc:0.91141\tvalidation_0-error:0.17318\tvalidation_0-error@0.6:0.16760\n",
      "[7]\tvalidation_0-auc:0.90650\tvalidation_0-error:0.18436\tvalidation_0-error@0.6:0.16760\n",
      "[8]\tvalidation_0-auc:0.90534\tvalidation_0-error:0.15643\tvalidation_0-error@0.6:0.17318\n",
      "[9]\tvalidation_0-auc:0.90560\tvalidation_0-error:0.16760\tvalidation_0-error@0.6:0.17318\n",
      "[10]\tvalidation_0-auc:0.90624\tvalidation_0-error:0.16760\tvalidation_0-error@0.6:0.17318\n",
      "[11]\tvalidation_0-auc:0.90198\tvalidation_0-error:0.16760\tvalidation_0-error@0.6:0.18436\n",
      "[12]\tvalidation_0-auc:0.89726\tvalidation_0-error:0.17318\tvalidation_0-error@0.6:0.17318\n",
      "[13]\tvalidation_0-auc:0.89435\tvalidation_0-error:0.16760\tvalidation_0-error@0.6:0.17318\n",
      "[14]\tvalidation_0-auc:0.88854\tvalidation_0-error:0.16760\tvalidation_0-error@0.6:0.17877\n",
      "[15]\tvalidation_0-auc:0.88621\tvalidation_0-error:0.16760\tvalidation_0-error@0.6:0.17877\n",
      "[16]\tvalidation_0-auc:0.88608\tvalidation_0-error:0.16760\tvalidation_0-error@0.6:0.17318\n",
      "[17]\tvalidation_0-auc:0.88285\tvalidation_0-error:0.17877\tvalidation_0-error@0.6:0.18436\n",
      "[18]\tvalidation_0-auc:0.87729\tvalidation_0-error:0.19553\tvalidation_0-error@0.6:0.18436\n",
      "[19]\tvalidation_0-auc:0.87846\tvalidation_0-error:0.19553\tvalidation_0-error@0.6:0.18436\n",
      "[20]\tvalidation_0-auc:0.87600\tvalidation_0-error:0.20112\tvalidation_0-error@0.6:0.18436\n",
      "[21]\tvalidation_0-auc:0.87329\tvalidation_0-error:0.20112\tvalidation_0-error@0.6:0.18436\n",
      "[22]\tvalidation_0-auc:0.87393\tvalidation_0-error:0.19553\tvalidation_0-error@0.6:0.18994\n",
      "[23]\tvalidation_0-auc:0.87342\tvalidation_0-error:0.19553\tvalidation_0-error@0.6:0.18994\n",
      "[24]\tvalidation_0-auc:0.87529\tvalidation_0-error:0.18994\tvalidation_0-error@0.6:0.17877\n",
      "[25]\tvalidation_0-auc:0.87387\tvalidation_0-error:0.19553\tvalidation_0-error@0.6:0.18436\n",
      "[26]\tvalidation_0-auc:0.87374\tvalidation_0-error:0.20112\tvalidation_0-error@0.6:0.18436\n",
      "[27]\tvalidation_0-auc:0.87322\tvalidation_0-error:0.20112\tvalidation_0-error@0.6:0.18436\n",
      "[28]\tvalidation_0-auc:0.87335\tvalidation_0-error:0.20670\tvalidation_0-error@0.6:0.18436\n",
      "[29]\tvalidation_0-auc:0.87452\tvalidation_0-error:0.20670\tvalidation_0-error@0.6:0.18994\n",
      "Xgb Accuracy: 79.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgboost.XGBClassifier(objective=\"binary:logistic\", n_estimators=30, random_state=42, eval_metric=[\"auc\", \"error\", \"error@0.6\"])\n",
    "xgb_model.fit(X_train, y_train, eval_set=[(X_test, y_test)])\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "xgb_accuracy = accuracy_score(y_test, y_pred_xgb)\n",
    "print(\"Xgb Accuracy: %.2f%%\" % (xgb_accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38d1c59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
